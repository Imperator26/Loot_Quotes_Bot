{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, ftplib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load private settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PATH and API_TOKEN\n",
    "from private_settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_TRANSACTIONS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://fenixweb.net:3300/api/v2/\"+API_TOKEN+\"/items\"\n",
    "response = json.loads(requests.get(url).text)\n",
    "\n",
    "assert response[\"code\"] == 200, \"Connection error.\"\n",
    "\n",
    "# Load json into dataframe\n",
    "items = pd.DataFrame(response[\"res\"])\n",
    "\n",
    "# Set id as index\n",
    "items.set_index(\"id\", inplace=True)\n",
    "\n",
    "items[\"datetime\"] = pd.to_datetime(\"now\")\n",
    "items[\"interval\"] = 2\n",
    "\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save items to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_csv(\"data/items.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request market transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://fenixweb.net:3300/api/v2/\"+API_TOKEN+\"/history/market_direct?limit=\"+str(NO_TRANSACTIONS)\n",
    "response = json.loads(requests.get(url).text)\n",
    "\n",
    "assert response[\"code\"] == 200, \"Connection error.\"\n",
    "\n",
    "transactions = pd.DataFrame(response[\"res\"])\n",
    "transactions.drop(columns=[\"buyer\", \"from_nick\", \"id\", \"name\", \"to_nick\", \"type\"], inplace=True)\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Develop cleaning process\n",
    "transactions = transactions.merge(items[[\"estimate\", \"rarity\", \"value\"]], left_on=\"item_id\", right_index=True, how=\"left\")\n",
    "# Remove items sold at the base price except for C type items\n",
    "transactions = transactions.query(\"rarity == 'C' | price != value\")\n",
    "# Remove items with price over 5 times the estimate except for U type\n",
    "transactions = transactions.query(\"rarity == 'U' | price < estimate*5\")\n",
    "\n",
    "# Drop estimate and values columns\n",
    "transactions.drop(columns=[\"estimate\", \"rarity\", \"value\"], inplace=True)\n",
    "\n",
    "# Set datetime as index\n",
    "transactions.time = pd.to_datetime(transactions.time, format=\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "transactions.set_index(\"time\", inplace=True)\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample transactions\n",
    "resampled_transactions = transactions.groupby(by=[\"item_id\"]).resample(\"2D\")\n",
    "#resampled_transactions.drop(columns=\"item_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: optimize\n",
    "numerosity = resampled_transactions.count()\n",
    "numerosity.rename(columns={\"price\":\"numerosity\"}, inplace=True)\n",
    "numerosity.drop(columns=\"item_id\", inplace=True)\n",
    "numerosity = numerosity.groupby(level=0).tail(1)\n",
    "numerosity.index = numerosity.index.droplevel(\"time\")\n",
    "\n",
    "numerosity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = resampled_transactions.mean()\n",
    "mean.rename(columns={\"price\":\"mean\"}, inplace=True)\n",
    "mean.drop(columns=\"item_id\", inplace=True)\n",
    "mean = mean.groupby(level=0).tail(1)\n",
    "mean.index = mean.index.droplevel(\"time\")\n",
    "mean = mean.groupby(level=0).tail(1)\n",
    "\n",
    "mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = resampled_transactions.std()\n",
    "std.rename(columns={\"price\":\"std\"}, inplace=True)\n",
    "std.drop(columns=\"item_id\", inplace=True)\n",
    "std = std.groupby(level=0).tail(1)\n",
    "std.index = std.index.droplevel(\"time\")\n",
    "std = std.groupby(level=0).tail(1)\n",
    "\n",
    "std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = resampled_transactions.median()\n",
    "median.rename(columns={\"price\":\"median\"}, inplace=True)\n",
    "median.drop(columns=\"item_id\", inplace=True)\n",
    "median = median.groupby(level=0).tail(1)\n",
    "median.index = median.index.droplevel(\"time\")\n",
    "median = median.groupby(level=0).tail(1)\n",
    "\n",
    "median.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_price = resampled_transactions.max()\n",
    "max_price.rename(columns={\"price\":\"max\"}, inplace=True)\n",
    "max_price.drop(columns=\"item_id\", inplace=True)\n",
    "max_price = max_price.groupby(level=0).tail(1)\n",
    "max_price.index = max_price.index.droplevel(\"time\")\n",
    "max_price = max_price.groupby(level=0).tail(1)\n",
    "\n",
    "max_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_price = resampled_transactions.min()\n",
    "min_price.rename(columns={\"price\":\"min\"}, inplace=True)\n",
    "min_price.drop(columns=\"item_id\", inplace=True)\n",
    "min_price = min_price.groupby(level=0).tail(1)\n",
    "min_price.index = min_price.index.droplevel(\"time\")\n",
    "min_price = min_price.groupby(level=0).tail(1)\n",
    "\n",
    "min_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_25 = resampled_transactions.agg(lambda x: x.quantile(0.25))\n",
    "quantile_25.rename(columns={\"price\":\"quantile_25\"}, inplace=True)\n",
    "quantile_25.drop(columns=\"item_id\", inplace=True)\n",
    "quantile_25 = quantile_25.groupby(level=0).tail(1)\n",
    "quantile_25.index = quantile_25.index.droplevel(\"time\")\n",
    "quantile_25 = quantile_25.groupby(level=0).tail(1)\n",
    "\n",
    "quantile_25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_75 = resampled_transactions.agg(lambda x: x.quantile(0.75))\n",
    "quantile_75.rename(columns={\"price\":\"quantile_75\"}, inplace=True)\n",
    "quantile_75.drop(columns=\"item_id\", inplace=True)\n",
    "quantile_75 = quantile_75.groupby(level=0).tail(1)\n",
    "quantile_75.index = quantile_75.index.droplevel(\"time\")\n",
    "quantile_75 = quantile_75.groupby(level=0).tail(1)\n",
    "\n",
    "quantile_75.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.merge(pd.concat([numerosity, mean, std, median, max_price, min_price, quantile_25, quantile_75], axis=1), left_index=True, right_index=True, how=\"left\")\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving market prices to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_json(\"data/market_prices.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save items statistics to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_row_to_csv(row):\n",
    "    if os.path.isfile(\"items/\"+str(row.name)+\".csv\"):\n",
    "        data = pd.read_csv(\"items/\"+str(row.name)+\".csv\")\n",
    "    else:\n",
    "        data = pd.DataFrame()\n",
    "    \n",
    "    data = data.append(row)\n",
    "    data.to_csv(\"items/\"+str(row.name)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items.apply(save_row_to_csv, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
